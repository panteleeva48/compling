{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['sarcasm', 'sarcastic-comments-on-reddit']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.externals import joblib\nimport nltk\nimport gensim\nimport spacy\nfrom tqdm import tqdm_notebook\n\nfrom sklearn import metrics\n\nimport torch as tt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torchtext.data import Field, LabelField, BucketIterator, ReversibleField, TabularDataset, Iterator\n\n\n\nSEED = 42\nnp.random.seed(SEED)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29a88ed6c3b5260ee72feb5dc34fa484a089aa42"
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('../input/sarcastic-comments-on-reddit/train-balanced-sarcasm.csv')",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9036abe3f98dc45c749983bd3862990427b94eb"
      },
      "cell_type": "code",
      "source": "#df[\"comment\"] = df[\"comment\"] + ' ' + df[\"parent_comment\"] + ' ' + df['subreddit']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4469423a4c964805be1ed6db38d92bf92afe575d"
      },
      "cell_type": "code",
      "source": "df = df[['label', 'comment']]",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f0876443c4de4ccf50584ccc93e32f3c866ad2c7"
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   label                                            comment\n0      0                                         NC and NH.\n1      0  You do know west teams play against west teams...\n2      0  They were underdogs earlier today, but since G...\n3      0  This meme isn't funny none of the \"new york ni...\n4      0                    I could use one of those tools.",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b08ffdc4a50f04b5bd3d5248e63d6c6e87cf7fa8"
      },
      "cell_type": "code",
      "source": "df.to_csv('my_data.csv', index=False)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9d59078bbb99daef0630a598ab4db656cae0b51"
      },
      "cell_type": "code",
      "source": "#df = pd.read_csv('my_data.csv')\n#df.head()",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "159221cc9c08da91b10c9f45a36cb612777ab78e"
      },
      "cell_type": "code",
      "source": "import spacy\n\n\nspacy_en = spacy.load('en')\nspacy_en.remove_pipe('tagger')\nspacy_en.remove_pipe('ner')\n\ndef tokenizer(text): # create a tokenizer function\n    return [tok.lemma_ for tok in spacy_en.tokenizer(text)]",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18b02df6903c8683f37cd42a800d716baad656a4"
      },
      "cell_type": "code",
      "source": "classes={\n    '0':0,\n    '1':1\n}\n\nTEXT = Field(include_lengths=True, batch_first=True, \n             tokenize=tokenizer,\n             eos_token='<eos>',\n             lower=True,\n             stop_words=nltk.corpus.stopwords.words('english')\n            )\nLABEL = LabelField(dtype=tt.int64, use_vocab=True, preprocessing=lambda x: classes[x])\n\ndataset = TabularDataset('my_data.csv', format='csv', \n                         fields=[('label', LABEL),('comment', TEXT)], \n                         skip_header=True)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bed157f919945631f84e0c9b62be136ca6ecd19c"
      },
      "cell_type": "code",
      "source": "TEXT.build_vocab(dataset, min_freq=5, vectors=\"glove.6B.300d\")\n# TEXT.build_vocab(dataset, min_freq=5)\nlen(TEXT.vocab.itos)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": ".vector_cache/glove.6B.zip: 862MB [01:26, 9.95MB/s]                               \n100%|█████████▉| 399634/400000 [00:51<00:00, 7843.11it/s]",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "35493"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80bb7e21b015023e9f94255eacbcdc9e58d59c54"
      },
      "cell_type": "code",
      "source": "TEXT.vocab.itos[:10]",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "['<unk>', '<pad>', '<eos>', '.', ',', '-pron-', '?', '!', '\"', '...']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f77cfc41e2b1b12c41dc13ccf1b2262738fb26c"
      },
      "cell_type": "code",
      "source": "LABEL.build_vocab(dataset)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6019ae8c4d8f33fa4512d26695cc596d20e02030"
      },
      "cell_type": "code",
      "source": "train, test = dataset.split(0.8, stratified=True)\ntrain, valid = train.split(0.9, stratified=True)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf2fe1bec366c1397cbcf0f9751eb2f605372b97"
      },
      "cell_type": "code",
      "source": "print(np.unique([x.label for x in train.examples], return_counts=True))\nprint(np.unique([x.label for x in valid.examples], return_counts=True))\nprint(np.unique([x.label for x in test.examples], return_counts=True))",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(array([0, 1]), array([363897, 363897]))\n(array([0, 1]), array([40433, 40433]))\n(array([0, 1]), array([101083, 101083]))\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf119dfeb177f6365cf2d4cb5d7bb0fb10468fc9"
      },
      "cell_type": "code",
      "source": "class MyModel(nn.Module):\n    \n    def __init__(self, vocab_size, embed_size, hidden_size, embedding, dropout=0):\n        super(MyModel, self).__init__()\n        self.embedding = nn.Embedding.from_pretrained(embedding, freeze=True)\n        \n        self.rnn = nn.LSTM(input_size=embed_size,\n                           hidden_size=hidden_size,\n                           bidirectional=True,\n                           batch_first=True,\n                           dropout = dropout\n                          )\n        \n        self.fc = nn.Linear(hidden_size * 2 * 2, 2)\n        \n    def forward(self, batch):\n        \n        x, x_lengths = batch.comment\n        \n        x = self.embedding(x)\n\n        if x_lengths is not None:\n            x_lengths = x_lengths.view(-1).tolist()\n            x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n            \n        _, (hidden, cell) = self.rnn(x)\n        \n        hidden = hidden.transpose(0,1)\n        cell = cell.transpose(0,1)\n        hidden = hidden.contiguous().view(hidden.size(0),-1)\n        cell = cell.contiguous().view(cell.size(0),-1)\n        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n        x = self.fc(x)\n        return x",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3882e81f74d2a883fb0417d4b442725a1f7240ca",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# tt.cuda.empty_cache()\n\nbatch_size = 64\npretrained_embedding = TEXT.vocab.vectors\nmodel = MyModel(len(TEXT.vocab.itos),\n                embed_size=300,\n                hidden_size=128, \n                embedding=pretrained_embedding\n               )\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train, valid, test),\n    batch_sizes=(batch_size, batch_size, batch_size),\n    shuffle=True,\n    sort_key=lambda x: len(x.comment),\n    sort_within_batch=True,\n)\n\noptimizer = optim.Adam(model.parameters())\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True, cooldown=5)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\ncriterion = nn.CrossEntropyLoss()",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "781dec3c2ca7d2d38268014be0b984204312e717"
      },
      "cell_type": "code",
      "source": "def _train_epoch(model, iterator, optimizer, criterion, curr_epoch):\n\n    model.train()\n\n    running_loss = 0\n\n    n_batches = len(iterator)\n    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n\n    for i, batch in enumerate(iterator):\n        optimizer.zero_grad()\n\n        pred = model(batch)\n        loss = criterion(pred, batch.label)\n        loss.backward()\n        optimizer.step()\n\n        curr_loss = loss.data.cpu().detach().item()\n        \n        loss_smoothing = i / (i+1)\n        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n\n        iterator.set_postfix(loss='%.5f' % running_loss)\n\n    return running_loss\n\ndef _test_epoch(model, iterator, criterion, scheduler):\n    model.eval()\n    epoch_loss = 0\n\n    n_batches = len(iterator)\n    with tt.no_grad():\n        for batch in iterator:\n            pred = model(batch)\n            loss = criterion(pred, batch.label)\n            epoch_loss += loss.data.item()\n    scheduler.step(epoch_loss)\n    \n    return epoch_loss / n_batches\n\n\ndef nn_train(model, train_iterator, valid_iterator, criterion, optimizer, n_epochs=100, \n             scheduler=None, early_stopping=0):\n\n    prev_loss = 100500\n    es_epochs = 0\n    best_epoch = None\n    history = pd.DataFrame()\n\n    for epoch in range(n_epochs):\n        train_loss = _train_epoch(model, train_iterator, optimizer, criterion, epoch)\n        valid_loss = _test_epoch(model, valid_iterator, criterion, scheduler)\n\n        valid_loss = valid_loss\n        print('validation loss %.5f' % valid_loss)\n\n        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n        history = history.append(record, ignore_index=True)\n\n        if early_stopping > 0:\n            if valid_loss > prev_loss:\n                es_epochs += 1\n            else:\n                es_epochs = 0\n\n            if es_epochs >= early_stopping:\n                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n                break\n\n            prev_loss = min(prev_loss, valid_loss)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d797ff848425a6c3da900f7a85e7c9965b9861e9"
      },
      "cell_type": "code",
      "source": "nn_train(model, train_iterator, valid_iterator, criterion, optimizer, n_epochs=50, \n         scheduler=scheduler, early_stopping=2)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 0', max=11372, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f8d7fd4c8334023b29b139ebc0ca7e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\r100%|█████████▉| 399634/400000 [01:10<00:00, 7843.11it/s]",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "validation loss 0.55972\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 1', max=11372, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9acf74ada08c4aeda46e4885f410cfcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "validation loss 0.55112\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 2', max=11372, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b12e0afd8a06493386f2982094c2307c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "validation loss 0.55390\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 3', max=11372, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a238a933c3a4451abd7f5155425cde4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "validation loss 0.55503\nEarly stopping! best epoch: 1 val 0.55112\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "829d5803fa8e11bedbd8c5b1ab81c12fcaee2444"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a6578755f0718a1d23af9d64d4817237dfec8bc"
      },
      "cell_type": "code",
      "source": "def evaluate(model, test_iterator, criterion):\n    model.eval()\n    epoch_acc = 0\n\n    n_batches = len(test_iterator)\n    with tt.no_grad():\n        for batch in test_iterator:\n            pred = model(batch)\n            pred = tt.softmax(pred, dim=-1)\n            pred = pred.detach().numpy()\n            acc = accuracy_score(batch.label, pred.argmax(axis=1))\n            epoch_acc += acc.item()\n\n    return epoch_acc / n_batches",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a36def85a7afc57d56e85178cec74abea0ff90de"
      },
      "cell_type": "code",
      "source": "acc = evaluate(model, test_iterator, criterion)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fcf4314e839a2a68866ae35fa251224a75700e6e"
      },
      "cell_type": "code",
      "source": "print('Accuracy on test sample:', acc)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy on test sample: 0.711720920825859\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
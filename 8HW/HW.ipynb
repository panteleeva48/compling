{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8\n",
    "Develop a model for 20 news groups dataset. Select 20% of data for test set.\n",
    "\n",
    "Use metric learning with siamese networks and triplet loss.\n",
    "\n",
    "Use KNN and LSH (annoy library) for final prediction after the network was trained.\n",
    "\n",
    "! Remember, that LSH gives you a set of neighbor candidates, for which you have to calculate distances to choose top-k nearest neighbors.\n",
    "\n",
    "Your quality = accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>topic</th>\n",
       "      <th>tokenized_message</th>\n",
       "      <th>lemmatized_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\r\\...</td>\n",
       "      <td>7</td>\n",
       "      <td>From where have my thing Subject WHAT car be t...</td>\n",
       "      <td>from where have my thing subject what car be t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>From Guy Kuo Subject SI Clock Poll Final Call ...</td>\n",
       "      <td>from guy kuo subject si clock poll final call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>From Thomas E Willis Subject PB question Organ...</td>\n",
       "      <td>from thomas e willis subject pb question organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\r\\nSubject: Re:...</td>\n",
       "      <td>1</td>\n",
       "      <td>From Joe Green Subject Re Weitek Organization ...</td>\n",
       "      <td>from joe green subject re weitek organization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>From Jonathan McDowell Subject Re Shuttle Laun...</td>\n",
       "      <td>from jonathan mcdowell subject re shuttle laun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  topic  \\\n",
       "0   0  From: lerxst@wam.umd.edu (where's my thing)\\r\\...      7   \n",
       "1   1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4   \n",
       "2   2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4   \n",
       "3   3  From: jgreen@amber (Joe Green)\\r\\nSubject: Re:...      1   \n",
       "4   4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14   \n",
       "\n",
       "                                   tokenized_message  \\\n",
       "0  From where have my thing Subject WHAT car be t...   \n",
       "1  From Guy Kuo Subject SI Clock Poll Final Call ...   \n",
       "2  From Thomas E Willis Subject PB question Organ...   \n",
       "3  From Joe Green Subject Re Weitek Organization ...   \n",
       "4  From Jonathan McDowell Subject Re Shuttle Laun...   \n",
       "\n",
       "                                  lemmatized_message  \n",
       "0  from where have my thing subject what car be t...  \n",
       "1  from guy kuo subject si clock poll final call ...  \n",
       "2  from thomas e willis subject pb question organ...  \n",
       "3  from joe green subject re weitek organization ...  \n",
       "4  from jonathan mcdowell subject re shuttle laun...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import spacy\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_en.remove_pipe('tagger')\n",
    "spacy_en.remove_pipe('ner')\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [tok.lemma_.lower() for tok in spacy_en.tokenizer(text) if tok.lemma_.isalpha()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokenized_messages = []\n",
    "for m in tqdm(df_test['message']):\n",
    "    tokenized_message = tokenizer(m)\n",
    "    tokenized_messages.append(' '.join(tokenized_message).strip())\n",
    "df_test['lemmatized_message'] = tokenized_messages\n",
    "df_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "import numpy as np\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchtext import data\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "elmo = Elmo(options_file, weight_file, 2, dropout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание триплетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist(emb1, emb2):\n",
    "    '''\n",
    "    compute the eucilidean distance matrix between embeddings\n",
    "    '''\n",
    "    m, n = emb1.shape[0], emb2.shape[0]\n",
    "    emb1_pow = tt.pow(emb1, 2).sum(dim = 1, keepdim = True).expand(m, n)\n",
    "    emb2_pow = tt.pow(emb2, 2).sum(dim = 1, keepdim = True).expand(n, m).t()\n",
    "    dist_mtx = emb1_pow + emb2_pow\n",
    "    dist_mtx = dist_mtx.addmm_(1, -2, emb1, emb2.t())\n",
    "    dist_mtx = tt.sqrt(dist_mtx.clamp(min = 1e-12))\n",
    "    return dist_mtx\n",
    "\n",
    "class TripletSelector(object):\n",
    "    '''\n",
    "    generate triplet\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(TripletSelector, self).__init__()\n",
    "\n",
    "    def __call__(self, embeds, labels):\n",
    "        dist_mtx = pdist(embeds, embeds).detach().cpu().numpy()\n",
    "        labels = labels.contiguous().cpu().numpy().reshape((-1, 1))\n",
    "        num = labels.shape[0]\n",
    "        dia_inds = np.diag_indices(num)\n",
    "        lb_eqs = labels == labels.T\n",
    "        lb_eqs[dia_inds] = False\n",
    "        dist_same = dist_mtx.copy()\n",
    "        dist_same[lb_eqs == False] = -np.inf\n",
    "        pos_idxs = np.argmax(dist_same, axis = 1)\n",
    "        dist_diff = dist_mtx.copy()\n",
    "        lb_eqs[dia_inds] = True\n",
    "        dist_diff[lb_eqs == True] = np.inf\n",
    "        neg_idxs = np.argmin(dist_diff, axis = 1)\n",
    "        pos = embeds[pos_idxs].contiguous().view(num, -1)\n",
    "        neg = embeds[neg_idxs].contiguous().view(num, -1)\n",
    "        return embeds, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = TripletSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor_embed, pos_embed, neg_embed):\n",
    "    loss = F.cosine_similarity(anchor_embed, neg_embed) - F.cosine_similarity(anchor_embed, pos_embed)\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "class Tripletnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tripletnet, self).__init__()\n",
    "        self.fc = nn.Linear(256*2, 128)\n",
    "        \n",
    "    def branch(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, anchor, pos, neg):\n",
    "        anchor = self.branch(anchor)\n",
    "        pos = self.branch(pos)\n",
    "        neg = self.branch(neg)\n",
    "        return triplet_loss(anchor, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_epoch(model, iterator, optimizer, curr_epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    iterator = tqdm(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        anchor, pos, neg = selector(batch[0], batch[1])\n",
    "        loss = model(anchor, pos, neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.data.cpu().detach().item()\n",
    "        \n",
    "        loss_smoothing = i / (i+1)\n",
    "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
    "\n",
    "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
    "\n",
    "    return running_loss\n",
    "\n",
    "def _test_epoch(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    with tt.no_grad():\n",
    "        for batch in iterator:\n",
    "            anchor, pos, neg = selector(batch[0], batch[1])\n",
    "            loss = model(anchor, pos, neg)\n",
    "            epoch_loss += loss.data.item()\n",
    "\n",
    "    return epoch_loss / n_batches\n",
    "\n",
    "\n",
    "def nn_train(model, train_iterator, valid_iterator, optimizer, n_epochs=100,\n",
    "          scheduler=None, early_stopping=0):\n",
    "\n",
    "    prev_loss = 100500\n",
    "    es_epochs = 0\n",
    "    best_epoch = None\n",
    "    history = pd.DataFrame()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = _train_epoch(model, train_iterator, optimizer, epoch)\n",
    "        valid_loss = _test_epoch(model, valid_iterator)\n",
    "\n",
    "        valid_loss = valid_loss\n",
    "        print('validation loss %.5f' % valid_loss)\n",
    "\n",
    "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
    "        history = history.append(record, ignore_index=True)\n",
    "\n",
    "        if early_stopping > 0:\n",
    "            if valid_loss > prev_loss:\n",
    "                es_epochs += 1\n",
    "            else:\n",
    "                es_epochs = 0\n",
    "\n",
    "            if es_epochs >= early_stopping:\n",
    "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
    "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
    "                break\n",
    "\n",
    "            prev_loss = min(prev_loss, valid_loss)\n",
    "    print('Saving model...')\n",
    "    tt.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27848976962941d093ae8c6b35047808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in tqdm(enumerate(df.lemmatized_message.values)):\n",
    "    x = batch_to_ids([text.split()])\n",
    "    x = elmo(x)['elmo_representations']\n",
    "    x = tt.cat(x, dim=-1)\n",
    "    x = x.mean(dim=1)\n",
    "    x = x.detach().numpy()\n",
    "    if i == 0:\n",
    "        data = x\n",
    "    else:\n",
    "        data = np.vstack((data, x))\n",
    "    if i % 100 == 0:\n",
    "        np.save('data.npy', data)\n",
    "np.save('data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data.npy')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Делим на train, validation и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, df.topic.values, random_state=SEED, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=SEED, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = TensorDataset(tt.tensor(X_train), tt.tensor(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataset = TensorDataset(tt.tensor(X_val), tt.tensor(y_val))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tripletnet()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee5033f2faf44ea8ff4478c320755d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 0', max=227, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss 0.00030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce52e19436974b00aa96d5fe61affea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1', max=227, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss 0.00018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474260a3a9d74c8a8e90cbe6b1af42a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 2', max=227, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss 0.00016\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Tripletnet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "nn_train(model, train_loader, val_loader, optimizer, n_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tt.load('model.pt')\n",
    "#_train = np.load('_train.npy')\n",
    "#_test = np.load('_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7240, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train = tt.from_numpy(X_train)\n",
    "_train = model.branch(_train).detach().numpy()\n",
    "np.save(\"_train.npy\", _train)\n",
    "_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2263, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test = tt.from_numpy(X_test)\n",
    "_test = model.branch(_test).detach().numpy()\n",
    "np.save(\"_test.npy\", _test)\n",
    "_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466b91ff277145bdb18faf76b858ff2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 128\n",
    "t = AnnoyIndex(f)\n",
    "for i, v in tqdm(enumerate(_train)):\n",
    "    t.add_item(i, v)\n",
    "t.build(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679d3467f2c9466f9b8b2e58f5cef55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.447635881573133\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i, v in tqdm(enumerate(_test)):\n",
    "    # находим индексы 20-и ближайших соседей\n",
    "    ids_nearest_neighbors = t.get_nns_by_vector(v, 10)\n",
    "    neighbor_vectors = []\n",
    "    # находим их эмбеддинги\n",
    "    for id_neighbor in ids_nearest_neighbors:\n",
    "        neighbor_v = _train[id_neighbor]\n",
    "        true_train = y_train[id_neighbor]\n",
    "        neighbor_vectors.append((true_train, neighbor_v))\n",
    "    # находим расстояние между вектором теста и каждым вектором ближашего соседа\n",
    "    probs = np.zeros(20)\n",
    "    for k, v_n in enumerate(neighbor_vectors):\n",
    "        dist = np.linalg.norm(v-v_n[1])\n",
    "        probs[v_n[0]] += dist\n",
    "    pred = np.argmax(probs)\n",
    "    if y_test[i] == pred:\n",
    "        accuracy += 1\n",
    "print('Accuracy:', accuracy/len(_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
